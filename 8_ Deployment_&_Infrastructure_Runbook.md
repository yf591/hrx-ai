
# 8. Deployment & Infrastructure Runbook

*バージョン: 1.0.0 | 最終更新日: 2025年5月14日*

ここではHRX-AIの安定した運用を実現するための、デプロイ手順、インフラ構成、障害対応手順などを具体的に示します。

## 目次

1.  [はじめに](#1-はじめに)
    *   1.1 本書の目的
    *   1.2 対象読者
    *   1.3 関連ドキュメント
2.  [インフラストラクチャ概要](#2-インフラストラクチャ概要)
    *   2.1 主要コンポーネントとホスティングプラットフォーム
    *   2.2 ネットワーク構成概要
    *   2.3 データストア構成
3.  [デプロイメントプロセス](#3-デプロイメントプロセス)
    *   3.1 CI/CDパイプライン概要
    *   3.2 フロントエンド (Next.js) のデプロイ
    *   3.3 バックエンド (Python FastAPI) のデプロイ
    *   3.4 AIモデルのデプロイと更新
    *   3.5 データベースのマイグレーション
    *   3.6 環境変数とシークレット管理
    *   3.7 ロールバック手順
4.  [運用監視とアラート](#4-運用監視とアラート)
    *   4.1 主要監視対象メトリクス
    *   4.2 監視ツールとダッシュボード
    *   4.3 アラート通知設定とエスカレーションパス
5.  [障害対応とSOP (Standard Operating Procedures)](#5-障害対応とsop-standard-operating-procedures)
    *   5.1 インシデント分類と優先度付け
    *   5.2 一般的な障害と対応手順
        *   5.2.1 フロントエンド応答なし/エラー
        *   5.2.2 バックエンドAPI応答なし/エラー
        *   5.2.3 データベース接続障害/高負荷
        *   5.2.4 AIモデル推論エラー/パフォーマンス低下
        *   5.2.5 外部サービス (Firebase/Supabase Auth, Stripe等) 障害
        *   5.2.6 セキュリティインシデントの疑い
    *   5.3 重大障害時のコミュニケーションプラン
6.  [バックアップとリカバリ](#6-バックアップとリカバリ)
    *   6.1 データバックアップ戦略
    *   6.2 リカバリ手順とRTO/RPO
    *   6.3 ディザスタリカバリ (DR) 計画の概要
7.  [メンテナンス作業](#7-メンテナンス作業)
    *   7.1 定期メンテナンス項目とスケジュール
    *   7.2 パッチ適用手順
    *   7.3 キャパシティプランニングとスケーリング
8.  [セキュリティ運用](#8-セキュリティ運用)
    *   8.1 定期的なセキュリティチェックリスト
    *   8.2 アクセス権レビュー手順
    *   8.3 ログレビューと不正アクセス監視
9.  [連絡先一覧](#9-連絡先一覧)
10. [付録](#10-付録)
    *   10.1 環境別設定値一覧 (主要なもの)
    *   10.2 トラブルシューティングFAQ

## 1. はじめに

*   **1.1 本書の目的**
    このドキュメントは、HRX-AIアプリケーションのデプロイメント、運用、および保守に関する手順とベストプラクティスを提供することを目的としています。システムの安定稼働を確保し、障害発生時の迅速な対応を支援します。

*   **1.2 対象読者**
    *   DevOpsエンジニア
    *   SRE (Site Reliability Engineer)
    *   システム運用担当者
    *   開発エンジニア (デプロイやトラブルシューティングに関わる場合)

*   **1.3 関連ドキュメント**
    *   `Development_Specification.md` (特にセクション2.5 インフラストラクチャ/DevOps, 4. アーキテクチャ設計, 12. 運用・非機能要件)
    *   `Architecture_&_Visual_Reference.md` (特にセクション3. システムアーキテクチャ図, 4. 技術スタック連携図, 17. モニタリング・オブザーバビリティフレームワーク)
    *   `6. Security Implementation Guide`
    *   `5. AI Integration Playbook` (特にセクション6. AIコンポーネントのデプロイ戦略, 8. AIシステムのモニタリングと観測可能性)

## 2. インフラストラクチャ概要

HRX-AIのインフラストラクチャは、スケーラビリティ、信頼性、セキュリティを重視して設計されています。主要なコンポーネントは以下の通りです。

*   **2.1 主要コンポーネントとホスティングプラットフォーム**
    *   **フロントエンド (Next.js)**
        *   ホスティング: Vercel (推奨) または Cloudflare Pages
        *   主な役割: UIレンダリング (SSR/CSR)、静的アセット配信、Next.js API Routes (エッジ関数)
    *   **バックエンド (Python FastAPI)**
        *   ホスティング: Railway (推奨) または Fly.io
        *   主な役割: ビジネスロジック処理、データベースアクセス、AIモデル連携、外部API連携
    *   **データベース (認証、リアルタイムDB、ストレージ含む)**
        *   サービス: Firebase (原則) または Supabase
        *   主な役割: ユーザー認証、構造化データ保存 (Firestore/PostgreSQL)、ファイルストレージ、リアルタイムデータ同期
    *   **AI/MLコンポーネント**
        *   LLM API: OpenAI (GPT-4o), Anthropic (Claude 3.x), Google (Gemini 2.0) などの外部API
        *   カスタムモデル/オープンソースモデル: Hugging Face Transformers, ONNX Runtime。必要に応じて Railway/Fly.io 上の専用サービス、またはGPU対応のクラウドVM (将来拡張)
        *   ベクトルデータベース: Supabase pgvector, Pinecone, Weaviate, またはクラウドプロバイダーのマネージドサービス
    *   **キャッシュ**
        *   サービス: Redis (Upstash 推奨)
        *   主な役割: APIレスポンスキャッシュ、セッションデータキャッシュ、頻繁アクセスデータキャッシュ
    *   **サブスクリプション課金**
        *   サービス: Stripe
    *   **CI/CD**
        *   サービス: GitHub Actions (推奨) または CircleCI
    *   **エッジコンピューティング/CDN**
        *   サービス: Vercel Edge Network, Cloudflare
        *   主な役割: 静的コンテンツ配信、エッジ関数実行、セキュリティ (WAF, DDoS対策)

*   **2.2 ネットワーク構成概要**
    *   ユーザーは主に Vercel/Cloudflare を経由してフロントエンドにアクセスします。
    *   フロントエンド (Next.js API Routes) は、必要に応じてバックエンド (FastAPI) に内部ネットワークまたはセキュアな公開API経由でリクエストを送信します。
    *   バックエンドサービスは、データベース、キャッシュ、外部LLM APIなどと通信します。これらの通信は原則としてTLSで暗号化されます。
    *   PaaSプラットフォーム (Vercel, Railway) を利用するため、詳細なネットワーク設定 (VPC, Subnetなど) はプラットフォーム側に委ねられる部分が多いですが、提供されるファイアウォールやIP制限機能は適切に設定します。
    *   データベース (Supabase/Firebase) へのアクセスは、アプリケーションサーバーのIPアドレスに制限することを推奨します。

*   **2.3 データストア構成**
    *   **プライマリデータベース (Firebase Firestore / Supabase PostgreSQL)**
        *   ユーザー情報、従業員データ、組織データ、パフォーマンスデータ、スキルデータなど、主要な構造化データを格納。
        *   定期的な自動バックアップを設定。
    *   **ベクトルデータベース (Supabase pgvector / 専用サービス)**
        *   RAGシステム用のドキュメント埋め込みベクトルを格納。
    *   **ファイルストレージ (Firebase Storage / Supabase Storage)**
        *   履歴書、職務経歴書、その他アップロードされたファイルを格納。
    *   **キャッシュ (Redis / Upstash)**
        *   一時的なデータ、セッション情報、頻繁にアクセスされるクエリ結果などを格納。

## 3. デプロイメントプロセス

`Development_Specification.md` の 2.5 インフラストラクチャ/DevOps「GitHub Actions/Circle CI: CI/CD自動化パイプライン」および 11.3 ブランチ戦略・リリースフローに基づき、自動化されたデプロイメントプロセスを構築します。

*   **3.1 CI/CDパイプライン概要 (GitHub Actions例)**
    1.  **トリガー**: `main`ブランチへのマージ (リリースブランチがある場合はそちら)、またはタグプッシュ。
    2.  **ビルド**
        *   フロントエンド (Next.js): `npm run build`
        *   バックエンド (Python FastAPI): Dockerイメージビルド (Dockerfileベース)
    3.  **テスト**
        *   ユニットテスト、統合テスト (各コンポーネント)
        *   静的コード解析 (ESLint, Pylint/Flake8/Black)
        *   依存関係脆弱性スキャン (npm audit, pip-audit)
        *   コンテナイメージスキャン (Trivyなど、バックエンドの場合)
    4.  **デプロイ (ステージング)**
        *   テスト成功後、ステージング環境へ自動デプロイ。
        *   Vercel: プレビューデプロイメントをステージングとして利用。
        *   Railway/Fly.io: ステージング用サービスにデプロイ。
    5.  **ステージング環境テスト**
        *   自動E2Eテスト実行。
        *   必要に応じて手動確認、UAT。
    6.  **デプロイ (本番)**
        *   ステージングテスト成功後、手動承認を経て本番環境へデプロイ (またはタグベースの自動デプロイ)。
        *   Vercel: `main`ブランチを本番デプロイメントに紐付け。
        *   Railway/Fly.io: 本番用サービスにデプロイ。
        *   **戦略**: ブルー/グリーンデプロイメントやカナリアリリースをプラットフォーム機能や設定で検討。
    7.  **ポストデプロイ**
        *   スモークテスト。
        *   キャッシュクリア (必要な場合)。
        *   監視システムへの通知。

*   **3.2 フロントエンド (Next.js) のデプロイ**
    *   **プラットフォーム**: Vercel (推奨)
    *   **手順**
        1.  GitHubリポジトリをVercelプロジェクトに接続。
        2.  ビルドコマンド: `next build` (通常は自動検出)。
        3.  出力ディレクトリ: `.next` (通常は自動検出)。
        4.  環境変数: Vercelのプロジェクト設定で、`NEXT_PUBLIC_*` プレフィックスのフロントエンド用環境変数と、サーバーサイドで利用するAPIキーなどのシークレットを設定。
        5.  デプロイフック: 必要に応じて、デプロイ完了後に外部システムへ通知するフックを設定。
    *   **ロールバック**: Vercelダッシュボードから過去のデプロイメントに即座にロールバック可能。

*   **3.3 バックエンド (Python FastAPI) のデプロイ**
    *   **プラットフォーム**: Railway (推奨) または Fly.io
    *   **手順 (Railway例)**
        1.  プロジェクトルートに `Dockerfile` と `railway.json` (またはRailwayダッシュボードで設定) を用意。
            ```dockerfile
            # Dockerfile (例)
            FROM python:3.11-slim
            WORKDIR /app
            COPY requirements.txt .
            RUN pip install --no-cache-dir -r requirements.txt
            COPY . .
            CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
            ```
            ```json
            // railway.json (例)
            // {
            //   "$schema": "https://railway.app/railway.schema.json",
            //   "build": {
            //     "builder": "DOCKERFILE",
            //     "dockerfilePath": "Dockerfile"
            //   },
            //   "deploy": {
            //     "startCommand": "uvicorn app.main:app --host 0.0.0.0 --port $PORT", // PORTはRailwayが提供
            //     "healthcheckPath": "/health", // ヘルスチェックエンドポイント
            //     "restartPolicyType": "ON_FAILURE",
            //     "restartPolicyMaxRetries": 10
            //   }
            // }
            ```
        2.  GitHubリポジトリをRailwayプロジェクトに接続、またはRailway CLIを使用。
        3.  環境変数: Railwayのプロジェクト設定で、データベース接続情報、外部APIキー、JWTシークレットなどを設定。
        4.  ヘルスチェックエンドポイント (`/health` など) をFastAPI側に実装し、Railwayに設定。
            ```python
            # app/main.py (ヘルスチェックエンドポイント例)
            # @app.get("/health")
            # async def health_check():
            #     return {"status": "healthy"}
            ```
    *   **ロールバック**: Railwayダッシュボードから過去のデプロイメントバージョンにロールバック可能。

*   **3.4 AIモデルのデプロイと更新**
    *   **外部LLM API**: 設定変更 (APIキー、モデルバージョンなど) は環境変数経由で行い、アプリケーションの再デプロイで反映。
    *   **カスタムモデル/オープンソースモデル**
        *   モデルファイルをオブジェクトストレージ (Firebase Storage / Supabase Storage) に保存し、バージョン管理。
        *   モデル推論サーバー (FastAPIサービスなど) をバックエンドと同様にRailway/Fly.ioにデプロイ。
        *   モデル更新時: 新しいモデルファイルをストレージにアップロードし、推論サーバーのコンフィグを更新して再デプロイ、またはブルー/グリーンデプロイメント戦略で切り替え。
        *   ONNX Runtime を使用する場合は、最適化された `.onnx` ファイルをデプロイパッケージに含めるか、ストレージからロード。
    *   **ベクトルデータベース**
        *   Supabase pgvector: 通常のデータベースマイグレーションプロセスでスキーマやインデックスを管理。データの再インデックスはバッチ処理として実行。
        *   専用ベクトルDBサービス: 各サービスのコンソールやAPI経由でインデックスを更新。
    *   参照: `5. AI Integration Playbook` セクション6. AIコンポーネントのデプロイ戦略

*   **3.5 データベースのマイグレーション**
    *   **Supabase (PostgreSQL)**
        *   Supabase CLI または Alembic, Django Migrations (もしDjangoを一部利用する場合) などのマイグレーションツールを使用。
        *   マイグレーションスクリプトはバージョン管理。
        *   CI/CDパイプラインで、デプロイ前にステージング環境でマイグレーションを実行・テスト。
        *   本番デプロイ時には、ダウンタイムを最小限にするため、アトミックなマイグレーションを心がける (例: ロック時間を短くする、オンラインスキーマ変更)。
        *   大規模なデータ移行や破壊的変更を伴う場合は、事前のバックアップと詳細な計画が必須。
    *   **Firebase Firestore (NoSQL)**
        *   スキーマレスだが、データの構造変更が必要な場合は、バッチスクリプトを作成してデータを更新・移行。
        *   インデックス定義は `firestore.indexes.json` で管理し、Firebase CLIでデプロイ。

*   **3.6 環境変数とシークレット管理**
    *   **原則**: ソースコードにシークレットをハードコーディングしない。
    *   **フロントエンド (Vercel)**: Vercelプロジェクト設定の環境変数。`NEXT_PUBLIC_` プレフィックスはブラウザでアクセス可能なので注意。サーバーサイドでのみ使用するシークレットにはプレフィックスを付けない。
    *   **バックエンド (Railway/Fly.io)**: プラットフォームの環境変数・シークレット管理機能。
    *   **Firebase/Supabase**: サービスアカウントキーファイルは安全な場所に保存し、CI/CD環境変数経由で利用。必要な権限のみを付与したサービスアカウントを使用。
    *   **外部APIキー (Stripe, LLMプロバイダーなど)**: 各プラットフォームのシークレット管理機能を利用。
    *   **ローカル開発**: `.env` ファイルを使用し、`.gitignore` に追加。`.env.example` に必要な変数のリストを記述。
    *   **将来的検討**: HashiCorp Vault やクラウドプロバイダーのシークレットマネージャー (AWS Secrets Manager, Google Secret Manager, Azure Key Vault) の導入。

*   **3.7 ロールバック手順**
    *   **フロントエンド (Vercel)**: Vercelダッシュボードから、任意の過去のデプロイメントを選択して即座にロールバック (トラフィックを切り替え)。
    *   **バックエンド (Railway/Fly.io)**: 各プラットフォームのダッシュボードから、過去のデプロイバージョンを選択してロールバック。
    *   **データベースマイグレーション**
        *   原則として、すべてのマイグレーションには対応するダウングレードスクリプトを用意する (Alembicなどでサポート)。
        *   ただし、データの損失を伴うダウングレードは困難なため、事前のバックアップと慎重なテストが重要。
        *   破壊的変更を伴うマイグレーションは、ブルー/グリーンデプロイメントと組み合わせるなど、より高度な戦略を検討。
    *   **AIモデル**: モデルレジストリでバージョン管理し、問題があれば以前のバージョンに切り替える。推論サーバーの設定を変更して再デプロイ。
    *   **ロールバック計画**
        1.  問題発生を検知。
        2.  影響範囲と深刻度を評価。
        3.  ロールバックの是非を判断 (ホットフィックスで対応可能か等)。
        4.  関連コンポーネント (フロントエンド、バックエンド、DBスキーマ) の整合性を考慮し、ロールバック対象と順序を決定。
        5.  各プラットフォームの手順に従いロールバックを実行。
        6.  動作確認。
        7.  原因分析と恒久対策の検討。

## 4. 運用監視とアラート

`Development_Specification.md` の 2.5 「OpenTelemetry」、12.1 「モニタリングアラートしきい値」、および `Architecture_&_Visual_Reference.md` の 17. 「モニタリング・オブザーバビリティフレームワーク」に基づき、システムの健全性とパフォーマンスを継続的に監視します。

*   **4.1 主要監視対象メトリクス**
    *   **フロントエンド (Vercel Analytics, Google Analyticsなど)**
        *   Web Vitals (LCP, FID, CLS)
        *   ページビュー数、ユニークユーザー数
        *   エラーレート (JavaScriptエラー)
        *   APIルート応答時間とエラーレート
    *   **バックエンドAPI (Railway/Fly.io組み込み監視, OpenTelemetry + Prometheus/Grafana)**
        *   APIリクエストレート (RPS)
        *   APIエラーレート (HTTP 4xx, 5xx)
        *   APIレイテンシ (平均、p90, p95, p99)
        *   CPU使用率、メモリ使用率、ディスクI/O (プラットフォームが提供)
        *   アクティブインスタンス数 (スケーリング状況)
    *   **データベース (Firebase/Supabaseコンソール, クラウド監視ツール)**
        *   クエリレイテンシ、スループット
        *   接続数
        *   ストレージ使用量
        *   CPU/メモリ使用率
        *   読み取り/書き込みIOPS
        *   バックアップ成功/失敗
    *   **AIモデル (カスタムメトリクス, LLMプロバイダー監視ダッシュボード)**
        *   推論レイテンシ
        *   推論エラーレート
        *   トークン使用量 (LLMの場合)
        *   モデル精度/ドリフト指標 (定期的なバッチ評価結果)
        *   RAGシステム: 検索ヒット率、チャンク関連度
    *   **キャッシュ (Upstashコンソールなど)**
        *   キャッシュヒット率
        *   レイテンシ
        *   メモリ使用量
    *   **キュー (もしあれば)**
        *   キューの長さ、メッセージ処理時間
    *   **セキュリティ関連**
        *   認証失敗レート
        *   WAFブロック数 (Cloudflare利用時)
        *   不審なIPからのアクセス試行

*   **4.2 監視ツールとダッシュボード**
    *   **OpenTelemetry**: アプリケーション全体 (フロントエンド、バックエンド) に計装を施し、トレース、メトリクス、ログを収集。
    *   **Prometheus**: OpenTelemetryからメトリクスを収集・保存する時系列データベース。
    *   **Grafana**: Prometheusや他のデータソース (Elasticsearch, Lokiなど) のデータを可視化するダッシュボードツール。カスタムダッシュボードを作成し、主要メトリクスを一覧表示。
    *   **各PaaSプラットフォームの監視ダッシュボード**: Vercel, Railway, Firebase/Supabaseなどが提供する組み込みの監視機能。
    *   **ログ管理システム**: Elastic Stack (Kibana) や Grafana Loki でログを検索・分析。
    *   **LLMプロバイダーのダッシュボード**: OpenAI, Anthropic, Googleなどが提供するAPI利用状況やパフォーマンス監視機能。

*   **4.3 アラート通知設定とエスカレーションパス**
    *   **アラートツール**: Grafana Alerting, Prometheus Alertmanager, またはクラウドプロバイダーのアラートサービス。
    *   **通知チャネル**: Slack (推奨), Eメール, PagerDuty (オンコール対応が必要な場合)。
    *   **アラート設定例 (閾値は要調整)**
        *   バックエンドAPIエラーレート > 5% (5分間継続) → Severity: Critical, Notify: Slackチャンネル `#hrx-alerts-critical`, PagerDuty
        *   バックエンドAPI p95レイテンシ > 2000ms (5分間継続) → Severity: Warning, Notify: Slackチャンネル `#hrx-alerts-warning`
        *   データベースCPU使用率 > 80% (10分間継続) → Severity: Warning, Notify: Slackチャンネル `#hrx-alerts-warning`
        *   Firebase/Supabase Auth 認証失敗レート > 10 RPS (1分間) → Severity: Critical (不正アクセス試行の可能性), Notify: Slackチャンネル `#hrx-security-alerts`, PagerDuty
        *   AIモデル推論エラーレート > 10% → Severity: Warning
        *   ディスク空き容量 < 10% → Severity: Critical
        *   SSL証明書有効期限 < 7日 → Severity: Warning
    *   **エスカレーションパス**
        1.  **自動アラート通知**: Slackチャンネルへ通知。
        2.  **一次対応者**: 運用チームメンバーが確認。SOPに従い初期対応。
        3.  **二次対応者 (エスカレーション)**: 問題が解決しない場合、または深刻度が高い場合、各コンポーネントの担当開発者やインフラ担当者にエスカレーション。
        4.  **インシデントマネージャー**: 重大障害時にはインシデントマネージャーが対応を統括。
    *   **オンコールローテーション**: 必要に応じてPagerDuty等でオンコール体制を構築。

## 5. 障害対応とSOP (Standard Operating Procedures)

`Development_Specification.md` 12.2 可用性・障害対応計画「障害検知・エスカレーションフロー」に基づき、障害発生時の対応手順を標準化します。

*   **5.1 インシデント分類と優先度付け**
    *   **Severity 1 (Critical / 重大)**
        *   定義: システム全体または主要機能が利用不可。広範囲なユーザーに影響。データ損失の可能性。セキュリティ侵害。
        *   目標対応開始時間 (SLAによる): 15分以内
        *   目標復旧時間 (RTO): 1時間以内 (状況による)
    *   **Severity 2 (Major / 重要)**
        *   定義: 主要機能の一部が利用不可または著しくパフォーマンスが低下。一部ユーザーに大きな影響。
        *   目標対応開始時間: 1時間以内
        *   目標復旧時間: 4時間以内
    *   **Severity 3 (Minor / 軽微)**
        *   定義: 非主要機能の不具合、または軽微なパフォーマンス低下。限定的なユーザーに影響。ワークアラウンドが存在。
        *   目標対応開始時間: 4時間以内 (営業時間内)
        *   目標復旧時間: 1営業日以内
    *   **Severity 4 (Trivial / ごく軽微)**
        *   定義: UIの軽微な不具合、ドキュメントの誤りなど。業務影響はほぼなし。
        *   目標対応開始時間: 1営業日以内
        *   目標復旧時間: 次回リリースまたは適宜

*   **5.2 一般的な障害と対応手順 (SOP)**

    各SOPには以下の情報を含めることを推奨
    *   障害の兆候・検知方法
    *   影響範囲の特定方法
    *   考えられる原因
    *   一次切り分け手順
    *   復旧手順 (暫定対応、恒久対応)
    *   エスカレーション基準と連絡先
    *   関連ログ・メトリクスの確認ポイント

    *   **5.2.1 フロントエンド応答なし/エラー (Vercelなど)**
        1.  **検知**: ユーザー報告、外部監視 (UptimeRobotなど)、Vercelダッシュボードのアラート。
        2.  **切り分け**
            *   Vercelステータスページ確認。
            *   Vercelデプロイメントログ確認。
            *   Cloudflareステータスページ確認 (利用時)。
            *   ブラウザ開発者ツールでネットワークエラー、コンソールエラー確認。
            *   特定のリージョンでのみ発生しているか確認。
        3.  **原因例**: Vercelプラットフォーム障害、デプロイ失敗、DNS設定ミス、フロントエンドコードのバグ、バックエンドAPI障害への依存。
        4.  **復旧手順**
            *   Vercel障害の場合: Vercelの復旧を待つ。必要に応じてユーザーに通知。
            *   デプロイ失敗/バグ: 問題のあるデプロイメントをロールバック。修正後再デプロイ。
            *   DNS問題: DNS設定を確認・修正。
            *   バックエンドAPI依存: バックエンドAPIのSOP (5.2.2) を参照。

    *   **5.2.2 バックエンドAPI応答なし/エラー (Railway/Fly.ioなど)**
        1.  **検知**: フロントエンドからのエラー報告、API監視アラート (レイテンシ、エラーレート)、ログ分析。
        2.  **切り分け**
            *   Railway/Fly.ioステータスページ確認。
            *   アプリケーションログ (FastAPIログ、Uvicornログ) 確認。`correlation_id` で関連ログを追跡。
            *   プラットフォームのメトリクス (CPU, メモリ, ディスク) 確認。
            *   データベース、キャッシュ、外部APIなど依存サービスの状況確認。
            *   特定のAPIエンドポイントのみの問題か、全体的な問題か。
        3.  **原因例**: Railway/Fly.ioプラットフォーム障害、デプロイ失敗、コードのバグ (無限ループ、メモリリークなど)、リソース枯渇、データベース接続障害、外部API障害。
        4.  **復旧手順**
            *   プラットフォーム障害の場合: 復旧を待つ。
            *   デプロイ失敗/バグ: 問題のあるデプロイをロールバック。修正後再デプロイ。
            *   リソース枯渇: インスタンスの再起動、スケールアップ/スケールアウト。原因調査と恒久対策。
            *   依存サービス障害: 各依存サービスのSOPを参照。

    *   **5.2.3 データベース接続障害/高負荷 (Firebase/Supabase)**
        1.  **検知**: APIエラーログ (DB接続エラー)、DB監視アラート (CPU使用率、接続数、スロークエリ)。
        2.  **切り分け**
            *   Firebase/Supabaseステータスページ確認。
            *   DBログ確認。
            *   アプリケーションサーバーからDBへのネットワーク接続確認。
            *   認証情報 (パスワード、接続文字列) の確認。
            *   高負荷の場合、実行中のクエリやコネクション数を確認。
        3.  **原因例**: Firebase/Supabaseプラットフォーム障害、ネットワーク障害、認証情報エラー、コネクションプール枯渇、非効率なクエリによる高負荷、インデックス不足。
        4.  **復旧手順**
            *   プラットフォーム障害: 復旧を待つ。
            *   認証情報エラー: 正しい認証情報に更新。
            *   コネクションプール枯渇: アプリケーションのコネクションプール設定見直し、DBインスタンスのスケールアップ。
            *   高負荷: 問題のあるクエリを特定し最適化 (EXPLAIN ANALYZE)。インデックス追加。リードレプリカの導入検討。DBインスタンスのスケールアップ。

    *   **5.2.4 AIモデル推論エラー/パフォーマンス低下 (LLM API, カスタムモデル)**
        1.  **検知**: APIエラーログ (モデル推論関連エラー)、監視アラート (推論レイテンシ、エラーレート)、ユーザー報告 (不適切な応答など)。
        2.  **切り分け**
            *   外部LLM APIの場合: プロバイダーのステータスページ確認。APIキーの有効性確認。リクエストペイロードの検証。
            *   カスタムモデルの場合: 推論サーバーのログ確認。リソース使用状況 (GPUメモリなど) 確認。入力データの検証。
            *   パフォーマンス低下の場合: リクエスト量、入力データのサイズ、モデル自体のバージョン変更などを確認。
        3.  **原因例**: LLM APIプロバイダー障害、APIキー無効/レート制限超過、不正な入力データ、モデルサーバーリソース不足、モデルのバグ、ネットワーク遅延。
        4.  **復旧手順**
            *   プロバイダー障害: 復旧を待つ。代替モデルへのフォールバックを検討。
            *   APIキー/レート制限: APIキー更新。レート制限緩和申請またはリクエスト頻度調整。
            *   不正な入力: 入力データ検証ロジックの強化。
            *   リソース不足: 推論サーバーのスケールアップ/アウト。
            *   モデルバグ: 問題のあるモデルバージョンをロールバック。修正後再デプロイ。

    *   **5.2.5 外部サービス (Firebase/Supabase Auth, Stripe等) 障害**
        1.  **検知**: 関連機能のエラー、外部サービスの監視アラート、ユーザー報告。
        2.  **切り分け**
            *   各サービスのステータスページ確認。
            *   APIキーや設定の確認。
            *   自社システムとの連携部分のログ確認。
        3.  **原因例**: 外部サービス自体の障害、API仕様変更、認証情報エラー、ネットワーク問題。
        4.  **復旧手順**
            *   外部サービス障害: 復旧を待つ。ユーザーへの影響を通知し、可能であれば一時的な代替手段を案内。
            *   設定/認証エラー: 設定を修正。
            *   API仕様変更: コードを修正し再デプロイ。

    *   **5.2.6 セキュリティインシデントの疑い (不正アクセス、データ漏洩など)**
        1.  **検知**: セキュリティ監視アラート (SIEM, WAF, IDS/IPS)、異常なログパターン、ユーザー/外部からの報告。
        2.  **対応**: `6. Security Implementation Guide` の「7.2 インシデント対応計画 (IRP)」に従い、迅速に対応チームを招集し、手順に沿って封じ込め、調査、復旧、報告を実施。

*   **5.3 重大障害時のコミュニケーションプラン**
    1.  **内部コミュニケーション**
        *   インシデント対応チーム内で専用Slackチャンネルやビデオ会議でリアルタイムに情報共有。
        *   経営層、関連部門リーダーへの定期的な状況報告 (JIRA Service Desk, ステータスページなど利用)。
    2.  **外部コミュニケーション (顧客向け)**
        *   **初期通知**: 問題発生と影響範囲を速やかに通知 (メール、システム内メッセージ、ステータスページ)。
        *   **進捗更新**: 定期的に (例: 30分～1時間ごと) 状況、対応進捗、復旧見込みを更新。
        *   **解決報告**: 問題解決後、原因と対策、再発防止策を報告。
        *   透明性と誠実さを重視。

## 6. バックアップとリカバリ

`Security Implementation Guide` 3.4 データバックアップとリカバリ および `Development_Specification.md` 12.2 可用性・障害対応計画「目標復旧時間（RTO）と目標復旧ポイント（RPO）」「バックアップ・リストア手順」に基づきます。

*   **6.1 データバックアップ戦略**
    *   **Firebase/Supabase**
        *   自動日次バックアップを有効化。
        *   ポイントインタイムリカバリ (PITR) を有効化 (可能な限り短い間隔、例: 5分～15分)。
        *   バックアップデータは、本番とは異なる地理的リージョンに冗長的に保存。
        *   保持期間: 少なくとも30日間 (法的要件やビジネス要件に応じて調整)。
    *   **ファイルストレージ**: Firebase/Supabase Storage のバージョン管理機能を利用。必要に応じて別途バックアップ。
    *   **ベクトルデータベース**: 利用するサービスが提供するバックアップ機能を利用。定期的にスナップショットを取得。
    *   **アプリケーション設定/コード**: Gitリポジトリでバージョン管理。CI/CDでデプロイされるため、コード自体はGitがバックアップとなる。環境変数やシークレットはプラットフォームの機能やVaultなどで管理・バックアップ。

*   **6.2 リカバリ手順とRTO/RPO**
    *   **目標復旧ポイント (RPO)**: 最大許容データ損失量。PITR設定により、数分～15分程度を目指す。
    *   **目標復旧時間 (RTO)**: システム復旧までの最大許容時間。障害の深刻度によるが、Severity 1で1時間、Severity 2で4時間を目指す (5.1参照)。
    *   **リカバリ手順**
        1.  障害発生の確認と影響範囲の特定。
        2.  バックアップからのリストアが必要か判断。
        3.  (Firebase/Supabaseの場合) プラットフォームのコンソールまたはCLIを使用して、適切なバックアップポイント (PITRまたは日次スナップショット) を選択し、リストアを開始。
        4.  リストア中、ユーザーにはメンテナンスモードを表示するか、影響を通知。
        5.  リストア完了後、データの整合性チェックとアプリケーションの動作確認。
        6.  段階的にトラフィックを戻し、監視を強化。
    *   **リカバリテスト**: 四半期に一度、ステージング環境などでリカバリテストを実施し、手順の有効性とRTO/RPOの達成可能性を検証。

*   **6.3 ディザスタリカバリ (DR) 計画の概要**
    *   **方針**: 大規模災害 (例: データセンター全体の障害) 発生時にも、事業継続を可能にするための計画。
    *   **実装 (段階的に検討)**
        *   **マルチリージョンバックアップ**: データバックアップを異なる地理的リージョンに保存 (実施済み)。
        *   **コールドスタンバイ/ウォームスタンバイ**: DRリージョンにインフラを準備しておき、有事の際に切り替える。
            *   コールド: インフラ定義はあるが、通常時はオフ。切り替えに時間がかかる。
            *   ウォーム: 最小限のインフラを起動状態に保ち、データは定期的に同期。コールドより迅速に切り替え可能。
        *   **ホットスタンバイ (マルチリージョンアクティブ/アクティブ)**: 複数のリージョンで同時にサービスを提供。最も高コストだが、ダウンタイムは最小。HRX-AIの初期フェーズでは過剰かもしれないが、将来的な選択肢。
        *   **DNSフェイルオーバー**: Route 53, Cloudflare DNSなどの機能を利用し、プライマリリージョン障害時にDRリージョンへトラフィックを自動または手動で切り替え。
        *   **DRテスト**: 年に1回程度、DR手順のテストを実施。

## 7. メンテナンス作業

システムの安定性とセキュリティを維持するための定期的なメンテナンス作業。

*   **7.1 定期メンテナンス項目とスケジュール**
    *   **OS/ランタイムパッチ適用 (Railway/Fly.ioが管理する部分以外)**: 原則としてPaaSが管理するが、カスタムDockerイメージ内のOSやライブラリは対象。月次で確認・適用。
    *   **依存ライブラリのアップデート**: 四半期に一度、またはセキュリティ脆弱性発見時に実施。Dependabotアラートをトリガーとする。
    *   **データベースメンテナンス**
        *   インデックスの再構築/最適化 (PostgreSQLの場合 `REINDEX`, `VACUUM ANALYZE`): 月次または必要に応じて。
        *   ストレージ容量監視とクリーンアップ: 週次。
    *   **セキュリティ証明書更新**: Vercel/Railwayなどは自動更新。手動管理の場合は有効期限を監視し、期限前に更新。
    *   **ログローテーションとアーカイブ**: ログ管理システムの設定に基づき自動実行。設定レビューは半年に一度。
    *   **不要なアカウント/リソースの棚卸し**: 四半期に一度。

*   **7.2 パッチ適用手順**
    1.  パッチ情報を収集・評価 (深刻度、影響範囲)。
    2.  ステージング環境でパッチを適用し、リグレッションテストを実施。
    3.  本番環境への適用計画を作成 (適用ウィンドウ、ロールバック手順)。
    4.  (必要であれば) ユーザーにメンテナンスウィンドウを通知。
    5.  本番環境にパッチを適用。
    6.  適用後の動作確認と監視。
    7.  問題発生時はロールバック手順を実行。

*   **7.3 キャパシティプランニングとスケーリング**
    *   **監視**: CPU, メモリ, ディスク, ネットワーク, データベース接続数などのリソース使用状況を継続的に監視。
    *   **トレンド分析**: 過去のリソース使用トレンドと将来のビジネス予測 (ユーザー数増加、機能追加など) に基づき、将来のキャパシティニーズを予測 (四半期ごと)。
    *   **スケーリング戦略**:
        *   **フロントエンド (Vercel)**: 通常、自動的にスケール。
        *   **バックエンド (Railway/Fly.io)**: オートスケーリング設定 (CPU/メモリベース) を適切に行う。垂直スケーリング (インスタンスタイプ変更) と水平スケーリング (インスタンス数増減) の両方を検討。
        *   **データベース (Firebase/Supabase)**: プラットフォームが提供するスケーリングオプションを利用。必要に応じてプランをアップグレード。リードレプリカの導入検討 (Supabase PostgreSQL)。シャーディングは大規模化した場合の将来的な選択肢。
        *   **AIモデル推論**: 必要に応じて推論サーバーのインスタンス数を調整。GPU利用の場合はGPUリソースの確保。
    *   **負荷テストによる検証**: 定期的な負荷テストで、現在のキャパシティとスケーリング設定の有効性を確認。

## 8. セキュリティ運用

`6. Security Implementation Guide` に基づく日常的なセキュリティ運用タスク。

*   **8.1 定期的なセキュリティチェックリスト**
    *   **日次**
        *   重要なセキュリティアラートの確認。
        *   認証失敗ログの確認 (異常な試行がないか)。
    *   **週次**
        *   WAFログ、ファイアウォールログのレビュー。
        *   主要なOS/ミドルウェアの脆弱性情報チェック。
        *   バックアップ成功確認。
    *   **月次**
        *   アクセスログの詳細レビュー (不審なアクセスパターンがないか)。
        *   セキュリティパッチ適用の確認。
        *   アンチウイルス定義ファイルの更新確認 (該当する場合)。
    *   **四半期**
        *   アクセス権限レビュー。
        *   セキュリティ設定 (ファイアウォールルール、DBセキュリティルールなど) のレビュー。
        *   インシデント対応計画のレビューと更新。

*   **8.2 アクセス権レビュー手順**
    1.  現在のユーザーリストと各ユーザーの役割・権限をエクスポート。
    2.  各部門長またはHR担当者と協力し、各ユーザーのアクセス権が業務上必要最小限であるかを確認。
    3.  不要なアカウントや過剰な権限を特定。
    4.  特定された問題を修正 (アカウント無効化、権限変更)。
    5.  レビュー結果と実施した変更を記録。

*   **8.3 ログレビューと不正アクセス監視**
    *   中央ログ管理システムで、セキュリティ関連のキーワード (例: "failed login", "unauthorized", "SQL injection attempt") を含むログをフィルタリングし、定期的にレビュー。
    *   異常なトラフィックパターン (例: 特定IPからの大量アクセス、海外からの予期せぬアクセス) を監視。
    *   不審なアクティビティ検知時には、詳細調査を行い、必要に応じてインシデント対応プロセスを開始。

## 9. 連絡先一覧

*   **インシデント対応チーム (IRT)**
    *   リーダー: [氏名、連絡先]
    *   技術担当 (インフラ): [氏名、連絡先]
    *   技術担当 (アプリ): [氏名、連絡先]
    *   セキュリティ担当: [氏名、連絡先]
    *   広報/法務担当 (必要に応じて): [氏名、連絡先]
*   **主要ベンダーサポート**
    *   Vercel: [サポートURL/連絡先]
    *   Railway/Fly.io: [サポートURL/連絡先]
    *   Firebase/Supabase: [サポートURL/連絡先]
    *   OpenAI/Anthropic/Google (LLM): [サポートURL/連絡先]
    *   Stripe: [サポートURL/連絡先]
*   **社内関連部門**
    *   開発チームリード: [氏名、連絡先]
    *   プロダクトオーナー: [氏名、連絡先]
    *   HR部門代表: [氏名、連絡先]

## 10. 付録

*   **10.1 環境別設定値一覧 (主要なもの)**
    *   各環境 (開発、ステージング、本番) のデータベース接続エンドポイント、APIエンドポイントURL、主要な設定パラメータなどを記載 (実際の値はシークレット管理)。
*   **10.2 トラブルシューティングFAQ**
    *   過去に発生した障害やよくある問題とその解決策をリスト化。
        *   例: 「Q: バックエンドAPIが503エラーを返す場合の確認ポイントは？ A: 1. Railway/Fly.ioのインスタンスステータス確認...」
